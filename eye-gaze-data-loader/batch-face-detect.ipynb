{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e675cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from batch_face import (\n",
    "    RetinaFace,\n",
    "    drawLandmark_multiple,\n",
    "    LandmarkPredictor,\n",
    "    SixDRep\n",
    ")\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "582aebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(face, landmark, pose, img):\n",
    "    head_pose = SixDRep(gpu_id=-1) # change from 0 to gpu_id=-1 for Mac users\n",
    "    print(face[1])\n",
    "    img = drawLandmark_multiple(img, face[0], landmark)\n",
    "    head_pose.plot_pose_cube(img, face[0], pose['pitch'], pose['yaw'], pose['roll'])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f934fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_eyes(face, img):\n",
    "    img = cv2.UMat(img).get()\n",
    "    features = face[1]\n",
    "    eyes = features[0], features[1]\n",
    "    # List to store cropped eyes\n",
    "    cropped_eyes = []\n",
    "    for eye in eyes:\n",
    "        # Round the coordinates to integers, as pixel indices must be integers\n",
    "        print(eye)\n",
    "        x = int(eye[0])\n",
    "        y = int(eye[1])\n",
    "\n",
    "        # Define the width and height of the rectangle to crop\n",
    "        width = 50  # Example width\n",
    "        height = 30  # Example height\n",
    "\n",
    "        # Compute the top-left corner of the rectangle\n",
    "        x_min = max(x - width // 2, 0)\n",
    "        y_min = max(y - height // 2, 0)\n",
    "\n",
    "        # Compute the bottom-right corner of the rectangle\n",
    "        x_max = min(x + width // 2, img.shape[1])\n",
    "        y_max = min(y + height // 2, img.shape[0])\n",
    "\n",
    "        # Crop the image using array slicing (OpenCV images are NumPy arrays)\n",
    "        cropped_eye = img[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        cropped_eyes.append(cropped_eye)\n",
    "    # Concatenate cropped eye images horizontally\n",
    "    if len(cropped_eyes) == 2:\n",
    "        concatenated_eyes = cv2.hconcat([cropped_eyes[0], cropped_eyes[1]])\n",
    "    else:\n",
    "        # If there are not exactly two eyes detected returm Npne\n",
    "        concatenated_eyes = None\n",
    "\n",
    "    return concatenated_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "016863d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_roi_box_from_bbox(bbox, img_shape):\n",
    "    h, w = img_shape\n",
    "    left, top, right, bottom = bbox\n",
    "    old_size = (right - left + bottom - top) / 2\n",
    "    center_x = right - (right - left) / 2.0\n",
    "    center_y = bottom - (bottom - top) / 2.0 + old_size * 0.14\n",
    "    size = int(old_size * 1.58)\n",
    "\n",
    "    roi_box = np.zeros((4))\n",
    "    roi_box[[0, 2]] = clip(center_x, size, w)\n",
    "    roi_box[[1, 3]] = clip(center_y, size, h)\n",
    "    return roi_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aaa633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, roi_box):\n",
    "    h, w = img.shape[:2]\n",
    "    print(roi_box)\n",
    "    sx, sy, ex, ey = [int(round(_)) for _ in roi_box]\n",
    "\n",
    "    dh, dw = ey - sy, ex - sx\n",
    "    if len(img.shape) == 3:\n",
    "        res = np.zeros((dh, dw, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        res = np.zeros((dh, dw), dtype=np.uint8)\n",
    "    if sx < 0:\n",
    "        sx, dsx = 0, -sx\n",
    "    else:\n",
    "        dsx = 0\n",
    "\n",
    "    if ex > w:\n",
    "        ex, dex = w, dw - (ex - w)\n",
    "    else:\n",
    "        dex = dw\n",
    "\n",
    "    if sy < 0:\n",
    "        sy, dsy = 0, -sy\n",
    "    else:\n",
    "        dsy = 0\n",
    "\n",
    "    if ey > h:\n",
    "        ey, dey = h, dh - (ey - h)\n",
    "    else:\n",
    "        dey = dh\n",
    "\n",
    "    res[dsy:dey, dsx:dex] = img[sy:ey, sx:ex]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc91411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(center, size, max_size):\n",
    "    end = center + size / 2\n",
    "    if end > max_size:\n",
    "        end = max_size\n",
    "    start = end - size\n",
    "    if start < 0:\n",
    "        start = 0\n",
    "        end = start + size\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac9dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(image):\n",
    "    result_list = []\n",
    "\n",
    "    predictor = LandmarkPredictor(gpu_id=-1)\n",
    "    detector = RetinaFace(gpu_id=-1)\n",
    "    head_pose = SixDRep(gpu_id=-1)\n",
    "\n",
    "    # Process a single image\n",
    "    img = image\n",
    "    all_faces = detector.pseudo_batch_detect([img], cv=True, threshold=0.9)\n",
    "    all_landmarks = predictor(all_faces, [img], from_fd=True)\n",
    "    all_poses = head_pose(all_faces, [img])\n",
    "\n",
    "    for faces, landmarks, pose in zip(all_faces, all_landmarks, all_poses):\n",
    "        for face, landmark, pose_data in zip(faces, landmarks, pose):\n",
    "            bbox = parse_roi_box_from_bbox(face[0], img.shape[:2])\n",
    "            concatenated_eyes = crop_eyes(face, img)\n",
    "            pitch, yaw, roll = pose_data['pitch'], pose_data['yaw'], pose_data['roll']\n",
    "            img_with_landmarks = draw_landmarks(face, landmark, pose_data, img.copy())\n",
    "\n",
    "            result = {\n",
    "                'p_pred_deg': [pitch],\n",
    "                'y_pred_deg': [yaw],\n",
    "                'r_pred_deg': [roll],\n",
    "                'image': concatenated_eyes,\n",
    "                'box': bbox.tolist(),\n",
    "                'landmarks': [l.tolist() for l in landmark]\n",
    "            }\n",
    "\n",
    "            result_list.append(result)\n",
    "\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e692fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270.83945 250.9438 ]\n",
      "[386.75488 303.01526]\n",
      "File Name: obama.png, Pitch: -10.937263488769531, Yaw: 5.830609321594238, Roll 23.617137908935547\n",
      "[214.21292 148.42426]\n",
      "[299.45154 146.22148]\n",
      "File Name: obama.jpg, Pitch: -13.801589965820312, Yaw: 0.683098554611206, Roll -1.1091930866241455\n",
      "[114.16702 121.60803]\n",
      "[156.342  121.8002]\n",
      "File Name: trump.jpg, Pitch: -12.918827056884766, Yaw: -8.755852699279785, Roll 1.0519715547561646\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    output_dir = \"./batch_img_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    predictor = LandmarkPredictor(gpu_id=-1) # change from 0 to gpu_id=-1 for Mac users\n",
    "    detector = RetinaFace(gpu_id=-1) # change from 0 to gpu_id=-1 for Mac users\n",
    "    head_pose = SixDRep(gpu_id=-1) # change from 0 to gpu_id=-1 for Mac users\n",
    "\n",
    "    all_images = []\n",
    "    names = os.listdir(\"batch_img_intake\")\n",
    "\n",
    "    for name in names:\n",
    "        img = cv2.imread(os.path.join(\"batch_img_intake\", name))\n",
    "        all_images.append(img)\n",
    "\n",
    "    all_faces = detector.pseudo_batch_detect(\n",
    "        all_images, cv=True, threshold=0.9\n",
    "    )  # batch input\n",
    "    all_results = predictor(all_faces, all_images, from_fd=True)\n",
    "    poses = head_pose(all_faces, all_images)\n",
    "\n",
    "    assert len(all_results) == len(all_faces)\n",
    "\n",
    "    for faces, landmarks, img, name, pose in zip(all_faces, all_results, all_images, names, poses):\n",
    "        assert len(faces) == len(landmarks)\n",
    "        \n",
    "        for face, landmark in zip(faces, landmarks):\n",
    "            ### Uncomment desired img function ###\n",
    "            #img = draw_landmarks(face,landmark,pose[0],img)\n",
    "            #box = parse_roi_box_from_bbox(face[0], img.shape[:2])\n",
    "            #img = crop_img(img, box)\n",
    "            img = crop_eyes(face,img)\n",
    "        cv2.imwrite(os.path.join(output_dir, name), img)\n",
    "        pitch, yaw, roll = (pose[0]['pitch'], pose[0]['yaw'], pose[0]['roll'])\n",
    "        print(f\"File Name: {name}, Pitch: {pitch}, Yaw: {yaw}, Roll {roll}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2742610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Eye-gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
