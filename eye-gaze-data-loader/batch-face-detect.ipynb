{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07e675cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from batch_face import (\n",
    "    RetinaFace,\n",
    "    drawLandmark_multiple,\n",
    "    LandmarkPredictor,\n",
    "    SixDRep\n",
    ")\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "582aebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(face, landmark, pose, img):\n",
    "    head_pose = SixDRep(0)\n",
    "    print(face[1])\n",
    "    img = drawLandmark_multiple(img, face[0], landmark)\n",
    "    head_pose.plot_pose_cube(img, face[0], pose['pitch'], pose['yaw'], pose['roll'])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b19542c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_eyes(face, img):\n",
    "    img = cv2.UMat(img).get()\n",
    "    features = face[1]\n",
    "    eyes = features[0], features[1]\n",
    "    # List to store cropped eyes\n",
    "    cropped_eyes = []\n",
    "    for eye in eyes:\n",
    "        # Round the coordinates to integers, as pixel indices must be integers\n",
    "        print(eye)\n",
    "        x = int(eye[0])\n",
    "        y = int(eye[1])\n",
    "\n",
    "        # Define the width and height of the rectangle to crop\n",
    "        width = 50  # Example width\n",
    "        height = 30  # Example height\n",
    "\n",
    "        # Compute the top-left corner of the rectangle\n",
    "        x_min = max(x - width // 2, 0)\n",
    "        y_min = max(y - height // 2, 0)\n",
    "\n",
    "        # Compute the bottom-right corner of the rectangle\n",
    "        x_max = min(x + width // 2, img.shape[1])\n",
    "        y_max = min(y + height // 2, img.shape[0])\n",
    "\n",
    "        # Crop the image using array slicing (OpenCV images are NumPy arrays)\n",
    "        cropped_eye = img[y_min:y_max, x_min:x_max]\n",
    "        cropped_eyes.append(cropped_eye)\n",
    "    # Concatenate cropped eye images horizontally\n",
    "    if len(cropped_eyes) == 2:\n",
    "        concatenated_eyes = cv2.hconcat([cropped_eyes[0], cropped_eyes[1]])\n",
    "    else:\n",
    "        # If there are not exactly two eyes detected returm Npne\n",
    "        concatenated_eyes = None\n",
    "\n",
    "    return concatenated_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "709daf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_roi_box_from_bbox(bbox, img_shape):\n",
    "    h, w = img_shape\n",
    "    left, top, right, bottom = bbox\n",
    "    old_size = (right - left + bottom - top) / 2\n",
    "    center_x = right - (right - left) / 2.0\n",
    "    center_y = bottom - (bottom - top) / 2.0 + old_size * 0.14\n",
    "    size = int(old_size * 1.58)\n",
    "\n",
    "    roi_box = np.zeros((4))\n",
    "    roi_box[[0, 2]] = clip(center_x, size, w)\n",
    "    roi_box[[1, 3]] = clip(center_y, size, h)\n",
    "    return roi_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ada965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, roi_box):\n",
    "    h, w = img.shape[:2]\n",
    "    print(roi_box)\n",
    "    sx, sy, ex, ey = [int(round(_)) for _ in roi_box]\n",
    "\n",
    "    dh, dw = ey - sy, ex - sx\n",
    "    if len(img.shape) == 3:\n",
    "        res = np.zeros((dh, dw, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        res = np.zeros((dh, dw), dtype=np.uint8)\n",
    "    if sx < 0:\n",
    "        sx, dsx = 0, -sx\n",
    "    else:\n",
    "        dsx = 0\n",
    "\n",
    "    if ex > w:\n",
    "        ex, dex = w, dw - (ex - w)\n",
    "    else:\n",
    "        dex = dw\n",
    "\n",
    "    if sy < 0:\n",
    "        sy, dsy = 0, -sy\n",
    "    else:\n",
    "        dsy = 0\n",
    "\n",
    "    if ey > h:\n",
    "        ey, dey = h, dh - (ey - h)\n",
    "    else:\n",
    "        dey = dh\n",
    "\n",
    "    res[dsy:dey, dsx:dex] = img[sy:ey, sx:ex]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70a59817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(center, size, max_size):\n",
    "    end = center + size / 2\n",
    "    if end > max_size:\n",
    "        end = max_size\n",
    "    start = end - size\n",
    "    if start < 0:\n",
    "        start = 0\n",
    "        end = start + size\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e692fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 25 (2187949622.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[80], line 31\u001b[1;36m\u001b[0m\n\u001b[1;33m    cv2.imwrite(os.path.join(output_dir, name), img)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 25\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    output_dir = \"./batch_img_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    predictor = LandmarkPredictor(0, \"PFLD\")\n",
    "    detector = RetinaFace(0)\n",
    "    head_pose = SixDRep(0)\n",
    "    all_images = []\n",
    "    names = os.listdir(\"batch_img_intake\")\n",
    "\n",
    "    for name in names:\n",
    "        img = cv2.imread(os.path.join(\"batch_img_intake\", name))\n",
    "        all_images.append(img)\n",
    "\n",
    "    all_faces = detector.pseudo_batch_detect(\n",
    "        all_images, cv=True, threshold=0.9\n",
    "    )  # batch input\n",
    "    all_results = predictor(all_faces, all_images, from_fd=True)\n",
    "    poses = head_pose(all_faces, all_images)\n",
    "\n",
    "    assert len(all_results) == len(all_faces)\n",
    "\n",
    "    for faces, landmarks, img, name, pose in zip(all_faces, all_results, all_images, names, poses):\n",
    "        assert len(faces) == len(landmarks)\n",
    "        \n",
    "        for face, landmark in zip(faces, landmarks):\n",
    "            ### Uncomment desired img function ###\n",
    "            #img = draw_landmarks(face,landmark,pose[0],img)\n",
    "            #box = parse_roi_box_from_bbox(face[0], img.shape[:2])\n",
    "            #img = crop_img(img, box)\n",
    "            img = crop_eyes(face,img)\n",
    "        cv2.imwrite(os.path.join(output_dir, name), img)\n",
    "        pitch, yaw, roll = (pose[0]['pitch'], pose[0]['yaw'], pose[0]['roll'])\n",
    "        print(f\"File Name: {name}, Pitch: {pitch}, Yaw: {yaw}, Roll {roll}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Eye-gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
