{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7f3b64-2f06-4eb1-8a79-77193c750e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import base64\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9f252f-599c-4d0a-b09c-d90c08bacfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_PERIOD = 100 # Number of Frames to Ignore Before Starting Detection\n",
    "\n",
    "pose_estimation_state = False  # True when target detected\n",
    "target_frames_counter = 0\n",
    "\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hol = mp.solutions.holistic\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "LEFT_IRIS = [474, 475, 476, 477,]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "\n",
    "LEFT_EYE = [7,33,246,161,160,159,158,157,173,133,155,154,153,145,144,163]\n",
    "LEFT_EYE_CONNECTIONS = [(LEFT_EYE[i], LEFT_EYE[i + 1]) for i in range(len(LEFT_EYE) - 1)]\n",
    "\n",
    "RIGHT_EYE = [362,398,384,385,386,387,388,466,263,249,390,373,374,380,381,382]\n",
    "RIGHT_EYE_CONNECTIONS = [(RIGHT_EYE[i], RIGHT_EYE[i + 1]) for i in range(len(RIGHT_EYE) - 1)]\n",
    "\n",
    "FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176,\n",
    "             149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]\n",
    "\n",
    "# Define Nose and Mouth connections\n",
    "NOSE = [0, 4, 6]\n",
    "NOSE_CONNECTIONS = [(NOSE[i], NOSE[i + 1]) for i in range(len(NOSE) - 1)]\n",
    "\n",
    "MOUTH_OUTER = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 61]\n",
    "MOUTH_OUTER_CONNECTIONS = [(MOUTH_OUTER[i], MOUTH_OUTER[i + 1]) for i in range(len(MOUTH_OUTER) - 1)]\n",
    "\n",
    "# Define connections based on the order of landmarks in FACE_OVAL\n",
    "FACE_OVAL_CONNECTIONS = [\n",
    "    (FACE_OVAL[i], FACE_OVAL[i + 1]) for i in range(len(FACE_OVAL) - 1)\n",
    "]\n",
    "# Add a connection between the last and first landmark to close the oval\n",
    "FACE_OVAL_CONNECTIONS.append((FACE_OVAL[-1], FACE_OVAL[0]))\n",
    "LEFT_EYE_CONNECTIONS.append((LEFT_EYE[-1], LEFT_EYE[0]))\n",
    "RIGHT_EYE_CONNECTIONS.append((RIGHT_EYE[-1], RIGHT_EYE[0]))\n",
    "\n",
    "# Add a scale factor for the iris circles\n",
    "scale_factor = 0.5\n",
    "\n",
    "custom_style = mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "custom_connections = list(mp_hol.POSE_CONNECTIONS)\n",
    "\n",
    "custom_face_landmark_style = DrawingSpec(color=(0, 0, 255), thickness=1)\n",
    "\n",
    "hand_connections_style = DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "\n",
    "excluded_pose_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "\n",
    "holistic = mp_hol.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "for landmark in excluded_pose_landmarks:\n",
    "    # Change the way the excluded landmarks are drawn\n",
    "    custom_style[landmark] = DrawingSpec(color=(255, 255, 0), thickness=None)\n",
    "    # Remove all connections which contain these landmarks\n",
    "    custom_connections = [\n",
    "        connection_tuple\n",
    "        for connection_tuple in custom_connections\n",
    "        if landmark not in connection_tuple\n",
    "    ]\n",
    "\n",
    "# Switch Between Detection On/Off State\n",
    "def switch_state(image):\n",
    "    global pose_estimation_state\n",
    "\n",
    "\n",
    "def draw(frame):\n",
    "    global pose_estimation_state\n",
    "    global target_frames_counter\n",
    "    global key_actions_detected\n",
    "\n",
    "    new_key_actions_detected = False\n",
    "\n",
    "    # Detection\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w = frame.shape[:2]\n",
    "    results = holistic.process(image)\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Pose Estimation State Transitions\n",
    "    if ((face_results.multi_face_landmarks or results.pose_landmarks) and not pose_estimation_state) or (not (face_results.multi_face_landmarks or results.pose_landmarks) and pose_estimation_state):\n",
    "        pose_estimation_state = not pose_estimation_state\n",
    "        target_frames_counter = 0\n",
    "\n",
    "    # No Need for Processing if No Target Found\n",
    "    if pose_estimation_state == False:\n",
    "        return (image)\n",
    "\n",
    "    # If Target Found, Increment Target Frames Counter\n",
    "    target_frames_counter = target_frames_counter + 1\n",
    "\n",
    "    # On New Target, Allow Buffer Period to Settle into Frame\n",
    "    if target_frames_counter < BUFFER_PERIOD:\n",
    "        return (image)\n",
    "\n",
    "    # Drawing Face, Nose and Mouth Connections\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # Draw Face Landmarks\n",
    "            for landmark_num in FACE_OVAL:\n",
    "                landmark = face_landmarks.landmark[landmark_num]\n",
    "                cv2.circle(image, (int(landmark.x * img_w), int(landmark.y * img_h)), 4, (0, 0, 255), -1)\n",
    "\n",
    "            # Draw Face Landmark Connections\n",
    "            for connection in FACE_OVAL_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Noses Landmark Connections\n",
    "            for connection in NOSE_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            #  Draw Mouth Landmark Connections\n",
    "            for connection in MOUTH_OUTER_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Hand Landmarks & Connections\n",
    "    mp_draw.draw_landmarks(image, results.right_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "    mp_draw.draw_landmarks(image, results.left_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "\n",
    "    # Draw Upper Body Pose Landmarks & Connections\n",
    "    if results.pose_landmarks:\n",
    "        # Draw Upper Body Pose Landmarks\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if landmark.visibility > 0.5:\n",
    "                if PoseLandmark(idx) not in excluded_pose_landmarks:\n",
    "                    cv2.circle(image, (int(landmark.x * img_w), int(landmark.y * img_h)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw Upper Body Pose Connections\n",
    "        for connection in custom_connections:\n",
    "            start = results.pose_landmarks.landmark[connection[0]]\n",
    "            end = results.pose_landmarks.landmark[connection[1]]\n",
    "            if (start.visibility > 0.5 and end.visibility > 0.5):\n",
    "                if (PoseLandmark(connection[0]) not in excluded_pose_landmarks and PoseLandmark(connection[1]) not in excluded_pose_landmarks):\n",
    "                    cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Irides\n",
    "    if face_results.multi_face_landmarks:\n",
    "        mesh_points = np.array([\n",
    "            np.multiply([p.x, p.y], [img_w, img_h]).astype(int)\n",
    "            for p in face_results.multi_face_landmarks[0].landmark\n",
    "        ])\n",
    "\n",
    "        (l_cx, l_cy), l_radius = cv2.minEnclosingCircle(mesh_points[LEFT_IRIS])\n",
    "        (r_cx, r_cy), r_radius = cv2.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n",
    "\n",
    "        center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    "        center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "\n",
    "        cv2.circle(image, center_left, int(l_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.circle(image, center_right, int(r_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b4878b-67f6-49da-9315-005bf2082eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw(frame):\n",
    "    global pose_estimation_state\n",
    "    global target_frames_counter\n",
    "    global key_actions_detected\n",
    "\n",
    "    new_key_actions_detected = False\n",
    "\n",
    "    # Detection\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w = frame.shape[:2]\n",
    "    results = holistic.process(image)\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    # Create a blank image with the same dimensions as the input frame\n",
    "    blank_image = np.zeros_like(frame)\n",
    "\n",
    "    # Pose Estimation State Transitions\n",
    "    if ((face_results.multi_face_landmarks or results.pose_landmarks) and not pose_estimation_state) or (not (face_results.multi_face_landmarks or results.pose_landmarks) and pose_estimation_state):\n",
    "        pose_estimation_state = not pose_estimation_state\n",
    "        target_frames_counter = 0\n",
    "\n",
    "    # No Need for Processing if No Target Found\n",
    "    if pose_estimation_state == False:\n",
    "        return blank_image\n",
    "\n",
    "    # If Target Found, Increment Target Frames Counter\n",
    "    target_frames_counter = target_frames_counter + 1\n",
    "\n",
    "    # On New Target, Allow Buffer Period to Settle into Frame\n",
    "    if target_frames_counter < BUFFER_PERIOD:\n",
    "        return blank_image\n",
    "\n",
    "    # Drawing Face, Nose, and Mouth Connections\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # Draw Face Landmarks\n",
    "            for landmark_num in FACE_OVAL:\n",
    "                landmark = face_landmarks.landmark[landmark_num]\n",
    "                cv2.circle(blank_image, (int(landmark.x * img_w), int(landmark.y * img_h)), 4, (0, 0, 255), -1)\n",
    "\n",
    "            # Draw Face Landmark Connections\n",
    "            for connection in FACE_OVAL_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Nose Landmark Connections\n",
    "            for connection in NOSE_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Mouth Landmark Connections\n",
    "            for connection in MOUTH_OUTER_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Eye Landmark Connections\n",
    "            for connection in LEFT_EYE_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end  = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            for connection in RIGHT_EYE_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end  = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "            \n",
    "\n",
    "    # Draw Hand Landmarks & Connections\n",
    "    mp_draw.draw_landmarks(blank_image, results.right_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "    mp_draw.draw_landmarks(blank_image, results.left_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "\n",
    "    # Draw Upper Body Pose Landmarks & Connections\n",
    "    if results.pose_landmarks:\n",
    "        # Draw Upper Body Pose Landmarks\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if landmark.visibility > 0.5:\n",
    "                if PoseLandmark(idx) not in excluded_pose_landmarks:\n",
    "                    cv2.circle(blank_image, (int(landmark.x * img_w), int(landmark.y * img_h)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw Upper Body Pose Connections\n",
    "        for connection in custom_connections:\n",
    "            start = results.pose_landmarks.landmark[connection[0]]\n",
    "            end = results.pose_landmarks.landmark[connection[1]]\n",
    "            if (start.visibility > 0.5 and end.visibility > 0.5):\n",
    "                if (PoseLandmark(connection[0]) not in excluded_pose_landmarks and PoseLandmark(connection[1]) not in excluded_pose_landmarks):\n",
    "                    cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Irides\n",
    "    if face_results.multi_face_landmarks:\n",
    "        mesh_points = np.array([\n",
    "            np.multiply([p.x, p.y], [img_w, img_h]).astype(int)\n",
    "            for p in face_results.multi_face_landmarks[0].landmark\n",
    "        ])\n",
    "\n",
    "        (l_cx, l_cy), l_radius = cv2.minEnclosingCircle(mesh_points[LEFT_IRIS])\n",
    "        (r_cx, r_cy), r_radius = cv2.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n",
    "\n",
    "        center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    "        center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "\n",
    "        cv2.circle(blank_image, center_left, int(l_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.circle(blank_image, center_right, int(r_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return blank_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426a3d26-2616-4d5f-9074-4ede1400ade5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\anaconda3\\envs\\sentinal\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Exit loop if frame reading fails\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Assuming you have a draw function to process the frame\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m processed_frame \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Display the processed frame\u001b[39;00m\n\u001b[0;32m     19\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRECEIVING VIDEO\u001b[39m\u001b[38;5;124m\"\u001b[39m, processed_frame)\n",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m, in \u001b[0;36mdraw\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m connection \u001b[38;5;129;01min\u001b[39;00m RIGHT_EYE_CONNECTIONS:\n\u001b[0;32m     66\u001b[0m             start \u001b[38;5;241m=\u001b[39m face_landmarks\u001b[38;5;241m.\u001b[39mlandmark[connection[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m---> 67\u001b[0m             end  \u001b[38;5;241m=\u001b[39m \u001b[43mface_landmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlandmark\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     68\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mline(blank_image, (\u001b[38;5;28mint\u001b[39m(start\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m img_w), \u001b[38;5;28mint\u001b[39m(start\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m img_h)), (\u001b[38;5;28mint\u001b[39m(end\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m*\u001b[39m img_w), \u001b[38;5;28mint\u001b[39m(end\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m*\u001b[39m img_h)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Draw Hand Landmarks & Connections\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, raw_frame = cap.read()  # Capture frame and check return value\n",
    "    if not ret:\n",
    "        print(\"Error reading frame. Check camera connection.\")\n",
    "        break  # Exit loop if frame reading fails\n",
    "\n",
    "    # Assuming you have a draw function to process the frame\n",
    "    processed_frame = draw(raw_frame)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"RECEIVING VIDEO\", processed_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b04fc-9f9e-4302-8806-68a6d8e4da41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f53a92-d1e8-4e67-8053-32f4cef91b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
