{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0a7f3b64-2f06-4eb1-8a79-77193c750e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import base64\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec\n",
    "from skimage import io\n",
    "from batch_face import RetinaFace, LandmarkPredictor, draw_landmarks, Timer\n",
    "import live_pose_estimator\n",
    "from live_pose_estimator import SixDRep\n",
    "import time\n",
    "import torch\n",
    "# USE Q TO EXIT PROGRAM AND F TO TOGGLE ADVANCED FACE MESH DISPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6ed98dce-8e1c-46a9-98e2-1de85d2fff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(frame, faces):\n",
    "    ### Predict landmarks from given face co-ordinates ###\n",
    "    landmarks = predictor(faces, frame, from_fd=True)\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d77b99ff-9bd8-49e7-b3a0-0dfe21f4ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_cv(frame, faces, landmarks):\n",
    "    ### Draw landmarks on faces using CV2 - Possible to draw multiple faces with a For loop, however we are only interested in having one face in the frame ### \n",
    "    frame = draw_landmarks(frame, faces[0][0], landmarks[0])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "79dac1b4-6891-4b16-a332-c66401c9fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_pose(frame, faces_pose):\n",
    "    head_poses = head_pose_estimator(faces_pose, frame, input_face_type='tuple', update_dict=True)\n",
    "    return head_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b3e1efeb-2912-4e6b-bd33-86bbef5f99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_head_pose_cube_cv(frame, faces, pose):\n",
    "    head_pose_estimator.plot_pose_cube(frame, faces[0][0], **pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a2d85e8e-2a63-469b-9b8c-bc09d1099f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_bbox(landmarks):\n",
    "    ldm_new = landmarks[0]\n",
    "    (x1, y1), (x2, y2) = ldm_new.min(0), ldm_new.max(0)\n",
    "    box_new = np.array([x1, y1, x2, y2])\n",
    "    box_new[:2] -= 10\n",
    "    box_new[2:] += 10\n",
    "    faces = [[box_new, None, None]]\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ae9f252f-599c-4d0a-b09c-d90c08bacfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_PERIOD = 100 # Number of Frames to Ignore Before Starting Detection\n",
    "\n",
    "pose_estimation_state = False  # True when target detected\n",
    "target_frames_counter = 0\n",
    "show_advanced_face_mesh_landmarks = False #Flag to show advanced face mesh for end-user to get a more detailed face mesh, purely visual for end user.\n",
    "\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hol = mp.solutions.holistic\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "LEFT_IRIS = [474, 475, 476, 477,]\n",
    "RIGHT_IRIS = [469, 470, 471, 472]\n",
    "\n",
    "LEFT_EYE = [7,33,246,161,160,159,158,157,173,133,155,154,153,145,144,163]\n",
    "LEFT_EYE_CONNECTIONS = [(LEFT_EYE[i], LEFT_EYE[i + 1]) for i in range(len(LEFT_EYE) - 1)]\n",
    "\n",
    "RIGHT_EYE = [362,398,384,385,386,387,388,466,263,249,390,373,374,380,381,382]\n",
    "RIGHT_EYE_CONNECTIONS = [(RIGHT_EYE[i], RIGHT_EYE[i + 1]) for i in range(len(RIGHT_EYE) - 1)]\n",
    "\n",
    "FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176,\n",
    "             149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]\n",
    "\n",
    "# Define Nose and Mouth connections\n",
    "NOSE = [0, 4, 6]\n",
    "NOSE_CONNECTIONS = [(NOSE[i], NOSE[i + 1]) for i in range(len(NOSE) - 1)]\n",
    "\n",
    "MOUTH_OUTER = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 61]\n",
    "MOUTH_OUTER_CONNECTIONS = [(MOUTH_OUTER[i], MOUTH_OUTER[i + 1]) for i in range(len(MOUTH_OUTER) - 1)]\n",
    "\n",
    "# Define connections based on the order of landmarks in FACE_OVAL\n",
    "FACE_OVAL_CONNECTIONS = [\n",
    "    (FACE_OVAL[i], FACE_OVAL[i + 1]) for i in range(len(FACE_OVAL) - 1)\n",
    "]\n",
    "# Add a connection between the last and first landmark to close the oval\n",
    "FACE_OVAL_CONNECTIONS.append((FACE_OVAL[-1], FACE_OVAL[0]))\n",
    "LEFT_EYE_CONNECTIONS.append((LEFT_EYE[-1], LEFT_EYE[0]))\n",
    "RIGHT_EYE_CONNECTIONS.append((RIGHT_EYE[-1], RIGHT_EYE[0]))\n",
    "\n",
    "# Add a scale factor for the iris circles\n",
    "scale_factor = 0.5\n",
    "\n",
    "custom_style = mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "custom_connections = list(mp_hol.POSE_CONNECTIONS)\n",
    "\n",
    "custom_face_landmark_style = DrawingSpec(color=(0, 0, 255), thickness=1)\n",
    "\n",
    "hand_connections_style = DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "\n",
    "excluded_pose_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "\n",
    "holistic = mp_hol.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "for landmark in excluded_pose_landmarks:\n",
    "    # Change the way the excluded landmarks are drawn\n",
    "    custom_style[landmark] = DrawingSpec(color=(255, 255, 0), thickness=None)\n",
    "    # Remove all connections which contain these landmarks\n",
    "    custom_connections = [\n",
    "        connection_tuple\n",
    "        for connection_tuple in custom_connections\n",
    "        if landmark not in connection_tuple\n",
    "    ]\n",
    "\n",
    "# Switch Between Detection On/Off State\n",
    "def switch_state(image):\n",
    "    global pose_estimation_state\n",
    "\n",
    "\n",
    "def draw(frame):\n",
    "    global pose_estimation_state\n",
    "    global target_frames_counter\n",
    "    global key_actions_detected\n",
    "\n",
    "    new_key_actions_detected = False\n",
    "\n",
    "    # Detection\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    img_h, img_w = frame.shape[:2]\n",
    "    results = holistic.process(image)\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Pose Estimation State Transitions\n",
    "    if ((face_results.multi_face_landmarks or results.pose_landmarks) and not pose_estimation_state) or (not (face_results.multi_face_landmarks or results.pose_landmarks) and pose_estimation_state):\n",
    "        pose_estimation_state = not pose_estimation_state\n",
    "        target_frames_counter = 0\n",
    "\n",
    "    # No Need for Processing if No Target Found\n",
    "    if pose_estimation_state == False:\n",
    "        return (image)\n",
    "\n",
    "    # If Target Found, Increment Target Frames Counter\n",
    "    target_frames_counter = target_frames_counter + 1\n",
    "\n",
    "    # On New Target, Allow Buffer Period to Settle into Frame\n",
    "    if target_frames_counter < BUFFER_PERIOD:\n",
    "        return (image)\n",
    "\n",
    "    # Drawing Face, Nose and Mouth Connections\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # Draw Face Landmarks\n",
    "            for landmark_num in FACE_OVAL:\n",
    "                landmark = face_landmarks.landmark[landmark_num]\n",
    "                cv2.circle(image, (int(landmark.x * img_w), int(landmark.y * img_h)), 4, (0, 0, 255), -1)\n",
    "\n",
    "            # Draw Face Landmark Connections\n",
    "            for connection in FACE_OVAL_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Noses Landmark Connections\n",
    "            for connection in NOSE_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            #  Draw Mouth Landmark Connections\n",
    "            for connection in MOUTH_OUTER_CONNECTIONS:\n",
    "                start = face_landmarks.landmark[connection[0]]\n",
    "                end = face_landmarks.landmark[connection[1]]\n",
    "                cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Hand Landmarks & Connections\n",
    "    mp_draw.draw_landmarks(image, results.right_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "    mp_draw.draw_landmarks(image, results.left_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "\n",
    "    # Draw Upper Body Pose Landmarks & Connections\n",
    "    if results.pose_landmarks:\n",
    "        # Draw Upper Body Pose Landmarks\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if landmark.visibility > 0.5:\n",
    "                if PoseLandmark(idx) not in excluded_pose_landmarks:\n",
    "                    cv2.circle(image, (int(landmark.x * img_w), int(landmark.y * img_h)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw Upper Body Pose Connections\n",
    "        for connection in custom_connections:\n",
    "            start = results.pose_landmarks.landmark[connection[0]]\n",
    "            end = results.pose_landmarks.landmark[connection[1]]\n",
    "            if (start.visibility > 0.5 and end.visibility > 0.5):\n",
    "                if (PoseLandmark(connection[0]) not in excluded_pose_landmarks and PoseLandmark(connection[1]) not in excluded_pose_landmarks):\n",
    "                    cv2.line(image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Irides\n",
    "    if face_results.multi_face_landmarks:\n",
    "        mesh_points = np.array([\n",
    "            np.multiply([p.x, p.y], [img_w, img_h]).astype(int)\n",
    "            for p in face_results.multi_face_landmarks[0].landmark\n",
    "        ])\n",
    "\n",
    "        (l_cx, l_cy), l_radius = cv2.minEnclosingCircle(mesh_points[LEFT_IRIS])\n",
    "        (r_cx, r_cy), r_radius = cv2.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n",
    "\n",
    "        center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    "        center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "\n",
    "        cv2.circle(image, center_left, int(l_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.circle(image, center_right, int(r_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e178da-2e23-47a2-bbfd-ed4cf3e25d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "09b4878b-67f6-49da-9315-005bf2082eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw(frame):\n",
    "    global pose_estimation_state\n",
    "    global target_frames_counter\n",
    "    global key_actions_detected\n",
    "    global show_advanced_face_mesh_landmarks  # Use the global flag here\n",
    "\n",
    "    new_key_actions_detected = False\n",
    "\n",
    "    # Detection\n",
    "    # Upload frame to GPU DOES NOT WORK DUE TO INCOMPATABILITY WITH VERSIONS D:\n",
    "    #gpu_frame = cv2.cuda_GpuMat()\n",
    "    #gpu_frame.upload(frame)\n",
    "    #gpu_frame = cv2.cuda.cvtColor(gpu_frame, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    img_h, img_w = frame.shape[:2]\n",
    "    #image = gpu_frame.download()  # Download image for further processing\n",
    "    results = holistic.process(image)\n",
    "    image.flags.writeable = True\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    # Create a blank image with the same dimensions as the input frame\n",
    "    blank_image = frame #originally np.zeros_like(frame)\n",
    "\n",
    "    # Pose Estimation State Transitions\n",
    "    if ((face_results.multi_face_landmarks or results.pose_landmarks) and not pose_estimation_state) or (not (face_results.multi_face_landmarks or results.pose_landmarks) and pose_estimation_state):\n",
    "        pose_estimation_state = not pose_estimation_state\n",
    "        target_frames_counter = 0\n",
    "\n",
    "    # No Need for Processing if No Target Found\n",
    "    if pose_estimation_state == False:\n",
    "        return blank_image\n",
    "\n",
    "    # If Target Found, Increment Target Frames Counter\n",
    "    target_frames_counter = target_frames_counter + 1\n",
    "\n",
    "    # On New Target, Allow Buffer Period to Settle into Frame\n",
    "    if target_frames_counter < BUFFER_PERIOD:\n",
    "        return blank_image\n",
    "\n",
    "    # Check if 'f' is pressed to toggle face landmarks, idk if we need this or not, it's just something i added, doesnt really slow down the program\n",
    "    if cv2.waitKey(10) & 0xFF == ord('f'):\n",
    "        show_advanced_face_mesh_landmarks = not show_advanced_face_mesh_landmarks  # Toggle the flag\n",
    "        \n",
    "    if show_advanced_face_mesh_landmarks and results.face_landmarks:\n",
    "        mp_draw.draw_landmarks(blank_image, results.face_landmarks, mp_hol.FACEMESH_TESSELATION, \n",
    "                                 mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "\n",
    "    # Drawing Face, Nose, and Mouth Connections/Deprecated/Superceded\n",
    "    #if face_results.multi_face_landmarks:\n",
    "    #    for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # Draw Face Landmarks/Deprecated/Superceded\n",
    "    #        for landmark_num in FACE_OVAL:\n",
    "    #            landmark = face_landmarks.landmark[landmark_num]\n",
    "    #            cv2.circle(blank_image, (int(landmark.x * img_w), int(landmark.y * img_h)), 4, (0, 0, 255), -1)\n",
    "\n",
    "            # Draw Face Landmark Connections/Disabled For Now/Deprecated\n",
    "            #for connection in FACE_OVAL_CONNECTIONS:\n",
    "            #    start = face_landmarks.landmark[connection[0]]\n",
    "            #    end = face_landmarks.landmark[connection[1]]\n",
    "            #    cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Nose Landmark Connections\n",
    "     #       for connection in NOSE_CONNECTIONS:\n",
    "      #          start = face_landmarks.landmark[connection[0]]\n",
    "       #         end = face_landmarks.landmark[connection[1]]\n",
    "        #        cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Mouth Landmark Connections\n",
    "         #   for connection in MOUTH_OUTER_CONNECTIONS:\n",
    "          #      start = face_landmarks.landmark[connection[0]]\n",
    "           #     end = face_landmarks.landmark[connection[1]]\n",
    "            #    cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw Eye Landmark Connections\n",
    "            #for connection in LEFT_EYE_CONNECTIONS:\n",
    "             #   start = face_landmarks.landmark[connection[0]]\n",
    "              #  end  = face_landmarks.landmark[connection[1]]\n",
    "               # cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "            #for connection in RIGHT_EYE_CONNECTIONS:\n",
    "             #   start = face_landmarks.landmark[connection[0]]\n",
    "              #  end  = face_landmarks.landmark[connection[1]]\n",
    "               # cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "            \n",
    "\n",
    "    # Draw Hand Landmarks & Connections\n",
    "    mp_draw.draw_landmarks(blank_image, results.right_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "    mp_draw.draw_landmarks(blank_image, results.left_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "\n",
    "    # Draw Upper Body Pose Landmarks & Connections\n",
    "    if results.pose_landmarks:\n",
    "        # Draw Upper Body Pose Landmarks\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if landmark.visibility > 0.5:\n",
    "                if PoseLandmark(idx) not in excluded_pose_landmarks:\n",
    "                    cv2.circle(blank_image, (int(landmark.x * img_w), int(landmark.y * img_h)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw Upper Body Pose Connections\n",
    "        for connection in custom_connections:\n",
    "            start = results.pose_landmarks.landmark[connection[0]]\n",
    "            end = results.pose_landmarks.landmark[connection[1]]\n",
    "            if (start.visibility > 0.5 and end.visibility > 0.5):\n",
    "                if (PoseLandmark(connection[0]) not in excluded_pose_landmarks and PoseLandmark(connection[1]) not in excluded_pose_landmarks):\n",
    "                    cv2.line(blank_image, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw Irides/Deprecated/Superceded\n",
    "    #if face_results.multi_face_landmarks:\n",
    "     #   mesh_points = np.array([\n",
    "      #      np.multiply([p.x, p.y], [img_w, img_h]).astype(int)\n",
    "       #     for p in face_results.multi_face_landmarks[0].landmark\n",
    "       # ])\n",
    "#\n",
    " #       (l_cx, l_cy), l_radius = cv2.minEnclosingCircle(mesh_points[LEFT_IRIS])\n",
    "  #      (r_cx, r_cy), r_radius = cv2.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n",
    "#\n",
    "   #     center_left = np.array([l_cx, l_cy], dtype=np.int32)\n",
    " #       center_right = np.array([r_cx, r_cy], dtype=np.int32)\n",
    "#\n",
    " #       cv2.circle(blank_image, center_left, int(l_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "  #      cv2.circle(blank_image, center_right, int(r_radius * scale_factor), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return blank_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "426a3d26-2616-4d5f-9074-4ede1400ade5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO face is detected!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\scout\\Desktop\\Sentinel_AI-main\\live_detection\\IMG_5307.mp4\")\n",
    "\n",
    "detector = RetinaFace(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "predictor = LandmarkPredictor(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "head_pose_estimator = SixDRep(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "detect_time = time.time()\n",
    "faces = None\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Capture frame and check return value\n",
    "    loop_time = time.time()\n",
    "    # Calculate the time difference\n",
    "    elapsed_time = time.time() - detect_time\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error reading frame. Check camera connection.\")\n",
    "        break  # Exit loop if frame reading fails\n",
    "     # Check if n seconds has passed: The shorter the elapsed time - the more face detections are done, but also the lower the fps and efficiency\n",
    "    if faces is None or elapsed_time >= 1:\n",
    "        faces = detector(frame, cv=True, threshold=0.5)\n",
    "        detect_time = time.time()\n",
    "    else:\n",
    "        ### This is an efficiency method of predicting the face bound-box - especially for live camera. It uses the min and max values from the results of the previous landmark 'predictor' function. Helps increase the fps rate ###\n",
    "        ### However, it will not detect new faces, or when a face has gone ###\n",
    "        faces = updated_bbox(landmarks)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"NO face is detected!\")\n",
    "        continue\n",
    "    ### Predict landmarks from face ###\n",
    "    landmarks = get_landmarks(frame, faces)\n",
    "\n",
    "    ### Estimate head pose from face ###\n",
    "    pose = get_head_pose(frame, faces)\n",
    "    \n",
    "    ### Draw landmarks (AND/OR) pose cube ###\n",
    "    frame = draw_landmarks_cv(frame, faces, landmarks)\n",
    "    draw_head_pose_cube_cv(frame, faces, pose[0])\n",
    "    # Assuming you have a draw function to process the frame\n",
    "    #!!!!!!the draw function makes the program pretty slow, not too sure how to fix or what is causing it.!!!!!!\n",
    "    #processed_frame = np.zeros_like(frame)\n",
    "    #when removing the line below and running the program, it is fast however only shows luke/nhat's tracking and not parts affinity.\n",
    "    #not too sure how to integrate better without as much stuttering :( additionally, not too sure how to overlay both parts shown with black image\n",
    "    processed_frame = draw(frame) #DISABLING THIS/ENABLING LINE ABOVE MAKES THE SCREEN BLACK/HIDES THE VIDEO AND SHOWS FACE/EYE TRACKING HOWEVER ONLY WITH NHAT/LUKE'S CODE\n",
    "    processed_frame = draw_landmarks_cv(processed_frame, faces, landmarks) #BASICALLY BREAKS ALL THE OTHER AFFINITY PARTS\n",
    "    draw_head_pose_cube_cv(processed_frame, faces, pose[0])\n",
    "    \n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"RECEIVING VIDEO\", frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37a446-2726-463a-b04f-f6504375cc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
