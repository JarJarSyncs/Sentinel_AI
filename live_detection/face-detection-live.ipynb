{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5fa286-347e-409c-a225-ee0698c65ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from batch_face import RetinaFace, LandmarkPredictor, draw_landmarks, Timer\n",
    "from live_pose_estimator import SixDRep\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a705e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mac users\n",
    "#import torch\n",
    "\n",
    "## Force CPU usage\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232b3c96-76e4-43ab-b747-2a7b464ece4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(frame, faces):\n",
    "    ### Predict landmarks from given face co-ordinates ###\n",
    "    landmarks = predictor(faces, frame, from_fd=True)\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d0b087-9816-4f11-88f1-2933902ac643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_cv(frame, faces, landmarks):\n",
    "    ### Draw landmarks on faces using CV2 - Possible to draw multiple faces with a For loop, however we are only interested in having one face in the frame ### \n",
    "    frame = draw_landmarks(frame, faces[0][0], landmarks[0])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22e115f-725e-4441-aa6e-6b27f035df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_pose(frame, faces_pose):\n",
    "    head_poses = head_pose_estimator(faces_pose, frame, input_face_type='tuple', update_dict=True)\n",
    "    return head_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecd1330-e11f-46e0-8bdb-3e3309af5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_head_pose_cube_cv(frame, faces, pose):\n",
    "    head_pose_estimator.plot_pose_cube(frame, faces[0][0], **pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2f7a89-bc2a-4924-8ea5-49852d29de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_bbox(landmarks):\n",
    "    ldm_new = landmarks[0]\n",
    "    (x1, y1), (x2, y2) = ldm_new.min(0), ldm_new.max(0)\n",
    "    box_new = np.array([x1, y1, x2, y2])\n",
    "    box_new[:2] -= 10\n",
    "    box_new[2:] += 10\n",
    "    faces = [[box_new, None, None]]\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfb5e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_face import (\n",
    "    RetinaFace,\n",
    ")\n",
    "from sixdrepnet.model import SixDRepNet\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import cos, sin\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sixdrepnet import utils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "detector = RetinaFace(gpu_id=0) # -1 for mac \n",
    "cam = 1\n",
    "device = torch.device('cuda') #-1 for mac\n",
    "model = SixDRepNet(backbone_name='RepVGG-B1g2',\n",
    "                   backbone_file='',\n",
    "                   deploy=True,\n",
    "                   pretrained=False)\n",
    "model.to(device)\n",
    "bw = False\n",
    "\n",
    "class SixthEyeNet(nn.ModuleList):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3)\n",
    "        self.pool = nn.MaxPool2d(3, 3)\n",
    "        self.conv2 = nn.Conv2d(9, 26, 3)\n",
    "        self.fc1 = nn.Linear(3432, 600)\n",
    "        self.fc2 = nn.Linear(600, 50)\n",
    "        self.fc3 = nn.Linear(53, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, head_pos = x\n",
    "        head_pos = head_pos\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.cat((x, head_pos), 1)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5630bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(image, offset_coeff=1) -> dict:\n",
    "    try:\n",
    "        coeff = 1280 / image.shape[1]\n",
    "        resized_image = cv2.resize(image, (1280, int(image.shape[0]*coeff)))\n",
    "        with torch.no_grad():\n",
    "            faces = detector(resized_image)\n",
    "            result = []\n",
    "            for box, landmarks, score in faces:\n",
    "\n",
    "                # Print the location of each face in this image\n",
    "                if score < .95:\n",
    "                    continue\n",
    "                x_min = int(box[0])\n",
    "                y_min = int(box[1])\n",
    "                x_max = int(box[2])\n",
    "                y_max = int(box[3])\n",
    "\n",
    "                x_min2 = int(box[0])\n",
    "                y_min2 = int(box[1])\n",
    "                x_max2 = int(box[2])\n",
    "                y_max2 = int(box[3])\n",
    "\n",
    "                x_3 = int(landmarks[0][0])\n",
    "                y_3 = int(landmarks[0][1])\n",
    "                x_4 = int(landmarks[1][0])\n",
    "                y_4 = int(landmarks[1][1])\n",
    "\n",
    "                bbox_width = abs(x_max - x_min)\n",
    "                bbox_height = abs(y_max - y_min)\n",
    "\n",
    "                x_min = max(0, x_min-int(0.2*bbox_height))\n",
    "                y_min = max(0, y_min-int(0.2*bbox_width))\n",
    "                x_max += int(0.2*bbox_height)\n",
    "                y_max += int(0.2*bbox_width)\n",
    "                img = resized_image[y_min:y_max, x_min:x_max]\n",
    "                img = Image.fromarray(img)\n",
    "                img = img.convert('RGB')\n",
    "                img = transformations(img)\n",
    "            \n",
    "                img = torch.Tensor(img[None, :]).to(device)\n",
    "                \n",
    "                R_pred = model(img)\n",
    "                \n",
    "                euler = utils.compute_euler_angles_from_rotation_matrices(\n",
    "                    R_pred)*180/np.pi\n",
    "                \n",
    "                curr = {'p_pred_deg': euler[:, 0].cpu(),\n",
    "                        'y_pred_deg': euler[:, 1].cpu(),\n",
    "                        'r_pred_deg': euler[:, 2].cpu()\n",
    "                        }\n",
    "                \n",
    "                offset = abs(((x_3 - x_min2)/2 + (x_max2-x_4)/2)/2)\n",
    "                x_offset = int(offset*1.2*offset_coeff)\n",
    "                y_offset = int(offset*0.8*offset_coeff)\n",
    "\n",
    "                y_3_min = int((y_3 - y_offset) / coeff)\n",
    "                y_3_max = int((y_3 + y_offset) / coeff)\n",
    "                x_3_min = int((x_3 - x_offset) / coeff)\n",
    "                x_3_max = int((x_3 + x_offset) / coeff)\n",
    "\n",
    "                y_4_min = int((y_4 - y_offset) / coeff)\n",
    "                y_4_max = int((y_4 + y_offset) / coeff)\n",
    "                x_4_min = int((x_4 - x_offset) / coeff)\n",
    "                x_4_max = int((x_4 + x_offset) / coeff)\n",
    "\n",
    "                right_eye = image[y_3_min:y_3_max, x_3_min: x_3_max]\n",
    "                left_eye = image[y_4_min:y_4_max, x_4_min: x_4_max]\n",
    "                left_eye = cv2.resize(\n",
    "                    left_eye, (right_eye.shape[1], right_eye.shape[0]))\n",
    "                curr['image'] = cv2.hconcat([right_eye, left_eye])\n",
    "                curr['box'] = list(map(lambda x: x/coeff, box))\n",
    "                curr['landmarks'] = list(\n",
    "                    map(lambda y: list(map(lambda x: x/coeff, y)), landmarks))\n",
    "                result.append(curr)\n",
    "    except Exception as e:\n",
    "        print(e.args)\n",
    "        return None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f90b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_eye_axis(img, yaw, pitch, roll, tdx, tdy, size=100):\n",
    "\n",
    "    pitch = pitch * np.pi / 180\n",
    "    yaw = -(yaw * np.pi / 180)\n",
    "    roll = roll * np.pi / 180\n",
    "\n",
    "    x = size * (sin(yaw)) + tdx\n",
    "    y = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x), int(y)), (255, 255, 0), 3)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80bae9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, yaw, pitch, roll, tdx=None, tdy=None, size = 100):\n",
    "\n",
    "    pitch = pitch * np.pi / 180\n",
    "    yaw = -(yaw * np.pi / 180)\n",
    "    roll = roll * np.pi / 180\n",
    "\n",
    "    if tdx != None and tdy != None:\n",
    "        tdx = tdx\n",
    "        tdy = tdy\n",
    "    else:\n",
    "        height, width = img.shape[:2]\n",
    "        tdx = width / 1.5\n",
    "        tdy = height / 1.5\n",
    "\n",
    "    # X-Axis pointing to right. drawn in red\n",
    "    x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "    y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "\n",
    "    # Y-Axis | drawn in green\n",
    "    #        v\n",
    "    x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "    y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "\n",
    "    # Z-Axis (out of the screen) drawn in blue\n",
    "    x3 = size * (sin(yaw)) + tdx\n",
    "    y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "\n",
    "    #cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),4)\n",
    "    #cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),4)\n",
    "    cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,69,0),7)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ecf6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_eye_gaze(face, net, affinity_frame):\n",
    "    box = face['box']\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    x_min = int(box[0])\n",
    "    y_min = int(box[1])\n",
    "    x_max = int(box[2])\n",
    "    y_max = int(box[3])\n",
    "\n",
    "    bbox_width = abs(x_max - x_min)\n",
    "    bbox_height = abs(y_max - y_min)\n",
    "\n",
    "    x_min = max(0, x_min-int(0.2*bbox_height))\n",
    "    y_min = max(0, y_min-int(0.2*bbox_width))\n",
    "    x_max += int(0.2*bbox_height)\n",
    "    y_max += int(0.2*bbox_width)\n",
    "\n",
    "    hp = face['p_pred_deg']\n",
    "    hy = face['y_pred_deg']\n",
    "    hr = face['r_pred_deg']\n",
    "\n",
    "    image = face['image']\n",
    "    image = cv2.resize(image, (210, 70),\n",
    "                        interpolation=cv2.INTER_CUBIC)\n",
    "    if bw:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = transforms(image).to(device)\n",
    "    # Check the devices of the inputs before the forward pass\n",
    "    head_pos = torch.unsqueeze(torch.tensor(\n",
    "        [float(hp), float(hr), float(hy)], dtype=torch.float32), dim=0).to(device)\n",
    "    image = torch.unsqueeze(image, dim=0).to(device)\n",
    "    res = net((image, head_pos))\n",
    "    res = res.tolist()[0]\n",
    "    pitch = res[0]\n",
    "    yaw = -res[1]\n",
    "    \n",
    "    print(pitch, yaw)\n",
    "\n",
    "    draw_axis(affinity_frame, yaw, pitch, hr,\n",
    "                    x_min+int(.5*(x_max-x_min)), y_min+int(.5*(y_max-y_min)), size=130)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e37bdccf-8d98-46e7-81c9-226f052b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_advanced_face_mesh_landmarks = False #Flag to show advanced face mesh for end-user to get a more detailed face mesh, purely visual for end user.\n",
    "\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_hol = mp.solutions.holistic\n",
    "\n",
    "custom_connections = list(mp_hol.POSE_CONNECTIONS)\n",
    "\n",
    "hand_connections_style = DrawingSpec(color=(0, 255, 0), thickness=2)\n",
    "\n",
    "excluded_pose_landmarks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "\n",
    "holistic = mp_hol.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def draw(live_frame, affinity_frame):\n",
    "    global pose_estimation_state\n",
    "    global target_frames_counter\n",
    "    global key_actions_detected\n",
    "    global show_advanced_face_mesh_landmarks  # Use the global flag here\n",
    "\n",
    "    # Detection\n",
    "    # Upload frame to GPU DOES NOT WORK DUE TO INCOMPATABILITY WITH VERSIONS D:\n",
    "    #gpu_frame = cv2.cuda_GpuMat()\n",
    "    #gpu_frame.upload(frame)\n",
    "    #gpu_frame = cv2.cuda.cvtColor(gpu_frame, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.cvtColor(live_frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    img_h, img_w = live_frame.shape[:2]\n",
    "    #image = gpu_frame.download()  # Download image for further processing\n",
    "    results = holistic.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Check if 'f' is pressed to toggle face landmarks, idk if we need this or not, it's just something i added, doesnt really slow down the program\n",
    "    if cv2.waitKey(10) & 0xFF == ord('f'):\n",
    "        show_advanced_face_mesh_landmarks = not show_advanced_face_mesh_landmarks  # Toggle the flag\n",
    "        \n",
    "    if show_advanced_face_mesh_landmarks and results.face_landmarks:\n",
    "        mp_draw.draw_landmarks(affinity_frame, results.face_landmarks, mp_hol.FACEMESH_TESSELATION, \n",
    "                                 mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "    \n",
    "     # Draw Hand Landmarks & Connections\n",
    "    mp_draw.draw_landmarks(affinity_frame, results.right_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "    mp_draw.draw_landmarks(affinity_frame, results.left_hand_landmarks, mp_hol.HAND_CONNECTIONS, connection_drawing_spec=hand_connections_style)\n",
    "\n",
    "    # Draw Upper Body Pose Landmarks & Connections\n",
    "    if results.pose_landmarks:\n",
    "        # Draw Upper Body Pose Landmarks\n",
    "        for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            if landmark.visibility > 0.5:\n",
    "                if PoseLandmark(idx) not in excluded_pose_landmarks:\n",
    "                    cv2.circle(affinity_frame, (int(landmark.x * img_w), int(landmark.y * img_h)), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Draw Upper Body Pose Connections\n",
    "        for connection in custom_connections:\n",
    "            start = results.pose_landmarks.landmark[connection[0]]\n",
    "            end = results.pose_landmarks.landmark[connection[1]]\n",
    "            if (start.visibility > 0.5 and end.visibility > 0.5):\n",
    "                if (PoseLandmark(connection[0]) not in excluded_pose_landmarks and PoseLandmark(connection[1]) not in excluded_pose_landmarks):\n",
    "                    cv2.line(affinity_frame, (int(start.x * img_w), int(start.y * img_h)), (int(end.x * img_w), int(end.y * img_h)), (0, 255, 0), 2)\n",
    "    return affinity_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f39a17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f1913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 4.10.0 =====================================\n",
      "  Version control:               4.10.0\n",
      "\n",
      "  Extra modules:\n",
      "    Location (extra):            D:/a/opencv-python/opencv-python/opencv_contrib/modules\n",
      "    Version control (extra):     4.10.0\n",
      "\n",
      "  Platform:\n",
      "    Timestamp:                   2024-06-17T18:00:01Z\n",
      "    Host:                        Windows 10.0.17763 AMD64\n",
      "    CMake:                       3.24.2\n",
      "    CMake generator:             Visual Studio 14 2015\n",
      "    CMake build tool:            MSBuild.exe\n",
      "    MSVC:                        1900\n",
      "    Configuration:               Debug Release\n",
      "\n",
      "  CPU/HW features:\n",
      "    Baseline:                    SSE SSE2 SSE3\n",
      "      requested:                 SSE3\n",
      "    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2\n",
      "      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX\n",
      "      SSE4_1 (16 files):         + SSSE3 SSE4_1\n",
      "      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2\n",
      "      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX\n",
      "      AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX\n",
      "      AVX2 (36 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      NO\n",
      "    C++ standard:                11\n",
      "    C++ Compiler:                C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe  (ver 19.0.24247.2)\n",
      "    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /O2 /Ob2 /DNDEBUG \n",
      "    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /Zi /Ob0 /Od /RTC1 \n",
      "    C Compiler:                  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\n",
      "    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /O2 /Ob2 /DNDEBUG \n",
      "    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /Zi /Ob0 /Od /RTC1 \n",
      "    Linker flags (Release):      /machine:x64  /NODEFAULTLIB:atlthunk.lib /INCREMENTAL:NO  /NODEFAULTLIB:libcmtd.lib /NODEFAULTLIB:libcpmtd.lib /NODEFAULTLIB:msvcrtd.lib\n",
      "    Linker flags (Debug):        /machine:x64  /NODEFAULTLIB:atlthunk.lib /debug /INCREMENTAL  /NODEFAULTLIB:libcmt.lib /NODEFAULTLIB:libcpmt.lib /NODEFAULTLIB:msvcrt.lib\n",
      "    ccache:                      NO\n",
      "    Precompiled headers:         YES\n",
      "    Extra dependencies:          wsock32 comctl32 gdi32 ole32 setupapi ws2_32\n",
      "    3rdparty dependencies:       libprotobuf ade ittnotify libjpeg-turbo libwebp libpng libtiff libopenjp2 IlmImf zlib ippiw ippicv\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape signal stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto\n",
      "    Disabled:                    java world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 alphamat cannops cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv freetype hdf julia matlab ovis python2 sfm ts viz\n",
      "    Applications:                -\n",
      "    Documentation:               NO\n",
      "    Non-free algorithms:         NO\n",
      "\n",
      "  Windows RT support:            NO\n",
      "\n",
      "  GUI:                           WIN32UI\n",
      "    Win32 UI:                    YES\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        build (ver 1.3.1)\n",
      "    JPEG:                        build-libjpeg-turbo (ver 3.0.3-70)\n",
      "      SIMD Support Request:      YES\n",
      "      SIMD Support:              NO\n",
      "    WEBP:                        build (ver encoder: 0x020f)\n",
      "    PNG:                         build (ver 1.6.43)\n",
      "      SIMD Support Request:      YES\n",
      "      SIMD Support:              YES (Intel SSE)\n",
      "    TIFF:                        build (ver 42 - 4.6.0)\n",
      "    JPEG 2000:                   build (ver 2.5.0)\n",
      "    OpenEXR:                     build (ver 2.3.0)\n",
      "    HDR:                         YES\n",
      "    SUNRASTER:                   YES\n",
      "    PXM:                         YES\n",
      "    PFM:                         YES\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394:                      NO\n",
      "    FFMPEG:                      YES (prebuilt binaries)\n",
      "      avcodec:                   YES (58.134.100)\n",
      "      avformat:                  YES (58.76.100)\n",
      "      avutil:                    YES (56.70.100)\n",
      "      swscale:                   YES (5.9.100)\n",
      "      avresample:                YES (4.0.0)\n",
      "    GStreamer:                   NO\n",
      "    DirectShow:                  YES\n",
      "    Media Foundation:            YES\n",
      "      DXVA:                      YES\n",
      "\n",
      "  Parallel framework:            Concurrency\n",
      "\n",
      "  Trace:                         YES (with Intel ITT)\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Intel IPP:                   2021.11.0 [2021.11.0]\n",
      "           at:                   D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.9/cmake-build/3rdparty/ippicv/ippicv_win/icv\n",
      "    Intel IPP IW:                sources (2021.11.0)\n",
      "              at:                D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.9/cmake-build/3rdparty/ippicv/ippicv_win/iw\n",
      "    Lapack:                      NO\n",
      "    Eigen:                       NO\n",
      "    Custom HAL:                  NO\n",
      "    Protobuf:                    build (3.19.1)\n",
      "    Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
      "\n",
      "  OpenCL:                        YES (NVD3D11)\n",
      "    Include path:                D:/a/opencv-python/opencv-python/opencv/3rdparty/include/opencl/1.2\n",
      "    Link libraries:              Dynamic load\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 C:/hostedtoolcache/windows/Python/3.9.13/x64/python.exe (ver 3.9.13)\n",
      "    Libraries:                   C:/hostedtoolcache/windows/Python/3.9.13/x64/libs/python39.lib (ver 3.9.13)\n",
      "    Limited API:                 YES (ver 0x03060000)\n",
      "    numpy:                       C:/hostedtoolcache/windows/Python/3.9.13/x64/lib/site-packages/numpy/_core/include (ver 2.0.0)\n",
      "    install path:                python/cv2/python-3\n",
      "\n",
      "  Python (for build):            C:\\hostedtoolcache\\windows\\Python\\3.9.13\\x64\\python.exe\n",
      "\n",
      "  Java:                          \n",
      "    ant:                         NO\n",
      "    Java:                        YES (ver 1.8.0.412)\n",
      "    JNI:                         C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.412-8/x64/include C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.412-8/x64/include/win32 C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.412-8/x64/include\n",
      "    Java wrappers:               NO\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Install to:                    D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.9/cmake-install\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba68f2c-8590-4610-8ac1-a01bc9eb1af5",
   "metadata": {},
   "source": [
    "Opens camera and passes frames to functions, comment/uncomment functions for desired tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfb35c8d-471b-4448-bb59-f17bb6426fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spookskiii\\AppData\\Local\\Temp\\ipykernel_3600\\867291252.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(EYE_MODEL_PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.016529083251953 0.11101677268743515\n",
      "-22.414222717285156 -11.37082290649414\n",
      "-24.22809600830078 -7.765000343322754\n",
      "-19.75263023376465 -5.324861526489258\n",
      "-21.600011825561523 -3.755385398864746\n",
      "-24.07997703552246 -3.1457579135894775\n",
      "-23.663419723510742 -2.9836950302124023\n",
      "-22.876117706298828 -3.7056872844696045\n",
      "-19.965925216674805 -2.3867428302764893\n",
      "-23.294145584106445 3.9738831520080566\n",
      "-22.95243263244629 -7.888794422149658\n",
      "-22.89484214782715 -5.209085941314697\n",
      "-22.80501365661621 -4.522103309631348\n",
      "-22.058324813842773 -6.145267486572266\n",
      "-21.32048225402832 -4.668886661529541\n",
      "-22.311908721923828 -7.458078861236572\n",
      "-20.839506149291992 -3.63850474357605\n",
      "-20.514352798461914 -3.0966858863830566\n",
      "-19.410627365112305 -0.8767509460449219\n",
      "-18.05751609802246 -3.1525533199310303\n",
      "-19.21438980102539 -1.0462682247161865\n",
      "-17.18753433227539 -1.663245439529419\n",
      "-17.942350387573242 -2.2920351028442383\n",
      "-16.59168815612793 -18.043699264526367\n",
      "-16.748689651489258 -16.148513793945312\n",
      "-17.32608985900879 -11.441363334655762\n",
      "-20.784976959228516 -0.5200302600860596\n",
      "-19.588516235351562 -1.5408539772033691\n",
      "-21.982572555541992 -4.596065044403076\n",
      "-19.041215896606445 18.4298095703125\n",
      "-6.751040458679199 26.694108963012695\n",
      "-18.376554489135742 20.272064208984375\n",
      "-20.938112258911133 14.45065689086914\n",
      "-17.247209548950195 2.062171459197998\n",
      "-19.848201751708984 1.27299165725708\n",
      "-16.14299774169922 7.254827499389648\n",
      "-14.95111083984375 -4.781469821929932\n",
      "-16.26309585571289 11.913031578063965\n",
      "-15.291324615478516 11.42259693145752\n",
      "-18.30829620361328 -9.298577308654785\n",
      "-18.70770835876465 -6.9081621170043945\n",
      "-15.997528076171875 -1.5907368659973145\n",
      "-18.435226440429688 -11.488846778869629\n",
      "-20.6412410736084 -14.148221969604492\n",
      "-22.74677276611328 -10.201420783996582\n",
      "-22.66990852355957 -4.867990493774414\n",
      "-22.13857650756836 -3.2046396732330322\n",
      "-20.307071685791016 -2.5210559368133545\n",
      "-15.17778205871582 -1.745725393295288\n",
      "-12.136720657348633 -4.192956924438477\n",
      "-12.733869552612305 1.9931645393371582\n",
      "-12.073249816894531 6.639336109161377\n",
      "-20.706443786621094 -9.321793556213379\n",
      "-15.443538665771484 -2.6561176776885986\n",
      "-16.64689064025879 -2.0311994552612305\n",
      "-14.436113357543945 -0.980332612991333\n",
      "-17.143022537231445 0.1758124977350235\n",
      "-21.369112014770508 1.3710553646087646\n",
      "-18.739654541015625 -1.4643027782440186\n",
      "-19.131071090698242 -0.17899297177791595\n",
      "-17.663196563720703 -3.526310682296753\n",
      "-20.590471267700195 11.133831977844238\n",
      "-19.95787239074707 18.575258255004883\n",
      "-16.873003005981445 15.789081573486328\n",
      "-20.16120147705078 16.726043701171875\n",
      "-19.292133331298828 -1.556795358657837\n",
      "-20.020204544067383 -1.6749646663665771\n",
      "-10.713007926940918 -5.35183048248291\n",
      "-9.43627643585205 -4.744756698608398\n",
      "-19.86717987060547 -0.3677944839000702\n",
      "-24.506526947021484 -10.46114730834961\n",
      "-19.88168716430664 -7.815893173217773\n",
      "-16.70393180847168 -1.3484318256378174\n",
      "-7.864690780639648 13.346964836120605\n",
      "6.544983386993408 25.878196716308594\n",
      "7.743062973022461 9.01472282409668\n",
      "10.715240478515625 4.214510917663574\n",
      "-17.96217155456543 4.095650672912598\n",
      "-14.68602466583252 7.283092021942139\n",
      "-13.021794319152832 8.254345893859863\n",
      "-13.33541488647461 -11.013774871826172\n",
      "-8.586257934570312 -7.621506214141846\n",
      "-10.682551383972168 3.2025697231292725\n",
      "-12.133245468139648 2.383542776107788\n",
      "-13.226137161254883 24.812641143798828\n",
      "-14.759017944335938 27.531204223632812\n",
      "-13.133718490600586 -0.06200907379388809\n",
      "-11.34289836883545 3.6299636363983154\n",
      "-10.390222549438477 -1.1374790668487549\n",
      "-12.533576965332031 0.9330260753631592\n",
      "-13.753145217895508 -0.37013790011405945\n",
      "-11.679182052612305 -2.3296103477478027\n",
      "-17.44468879699707 -6.432040214538574\n",
      "-14.955370903015137 -6.658563613891602\n",
      "-21.268339157104492 -6.767333984375\n",
      "-22.46072769165039 -7.87919807434082\n",
      "-21.353628158569336 -6.951033115386963\n",
      "-19.30963134765625 -1.2393889427185059\n",
      "-20.110767364501953 -3.049039363861084\n",
      "-19.27496910095215 -4.101034164428711\n",
      "-20.147871017456055 -2.562979221343994\n",
      "-22.15514373779297 -8.263400077819824\n",
      "-15.46561050415039 -4.056730270385742\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "-10.925495147705078 1.8288283348083496\n",
      "-11.363748550415039 4.945437431335449\n",
      "-12.78457260131836 6.48192024230957\n",
      "-8.584868431091309 7.702714920043945\n",
      "-7.650099277496338 9.837867736816406\n",
      "-2.177964687347412 6.857159614562988\n",
      "-6.0561113357543945 16.296863555908203\n",
      "-11.889122009277344 14.387208938598633\n",
      "-15.316452026367188 10.726900100708008\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "-0.7677087783813477 20.22769546508789\n",
      "-2.1931076049804688 19.411819458007812\n",
      "2.27443790435791 20.11275291442871\n",
      "2.5107696056365967 17.556167602539062\n",
      "-2.197997808456421 20.37417221069336\n",
      "0.317488431930542 19.29891014099121\n",
      "2.0807127952575684 19.166667938232422\n",
      "-1.1994969844818115 15.624093055725098\n",
      "-2.879866361618042 16.982418060302734\n",
      "-1.407813549041748 17.076679229736328\n",
      "-2.2598628997802734 10.370529174804688\n",
      "-3.7518181800842285 22.012493133544922\n",
      "-6.675301551818848 8.285205841064453\n",
      "-2.818357229232788 11.12295150756836\n",
      "-3.9568185806274414 12.137002944946289\n",
      "-8.802030563354492 -2.055414915084839\n",
      "-8.649709701538086 4.030341625213623\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "NO face is detected!\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "-10.188283920288086 -0.6235592365264893\n",
      "-7.251124382019043 10.05957317352295\n",
      "-5.355740547180176 10.00218677520752\n",
      "0.7024354338645935 10.446574211120605\n",
      "0.06581956148147583 11.592296600341797\n",
      "-7.536655426025391 19.185157775878906\n",
      "-2.2533230781555176 9.21256160736084\n",
      "-10.47294807434082 10.643584251403809\n",
      "-5.289177894592285 6.108689785003662\n",
      "0.6995163559913635 13.471663475036621\n",
      "0.7743330597877502 15.88809871673584\n",
      "1.074028730392456 16.348220825195312\n",
      "0.5533506870269775 24.06449317932129\n",
      "-1.5987062454223633 18.783004760742188\n",
      "4.492686748504639 18.06942367553711\n",
      "-4.3335418701171875 23.889101028442383\n",
      "-3.026662588119507 32.52845001220703\n",
      "-2.782069206237793 32.0367431640625\n",
      "-1.9414520263671875 33.08686065673828\n",
      "-0.9322361946105957 32.8232421875\n",
      "-6.301987648010254 6.4674458503723145\n",
      "-6.324857711791992 9.378154754638672\n",
      "-5.938232421875 10.09512996673584\n",
      "-3.8689427375793457 7.8567681312561035\n",
      "-7.545215606689453 14.365630149841309\n",
      "-6.009579658508301 13.999906539916992\n",
      "0.0008026324212551117 9.052586555480957\n",
      "-2.854668617248535 6.305444240570068\n",
      "-1.888663411140442 8.284717559814453\n",
      "-11.306472778320312 -6.31083869934082\n",
      "-14.019369125366211 20.68874740600586\n",
      "-11.196985244750977 22.96723175048828\n",
      "-17.27055549621582 13.621254920959473\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "-8.362871170043945 12.012238502502441\n",
      "-12.693102836608887 16.597492218017578\n",
      "NO face is detected!\n",
      "-0.11355412006378174 -19.197620391845703\n",
      "-19.86471939086914 18.107309341430664\n",
      "-14.708221435546875 16.256839752197266\n",
      "-9.384857177734375 24.807758331298828\n",
      "-14.042141914367676 16.232057571411133\n",
      "-9.096208572387695 10.85159969329834\n",
      "-9.26562786102295 17.267662048339844\n",
      "-10.109859466552734 16.619773864746094\n",
      "-12.574057579040527 12.860995292663574\n",
      "-11.164073944091797 6.389160633087158\n",
      "-14.323101043701172 16.762210845947266\n",
      "-11.969751358032227 19.310890197753906\n",
      "-13.392297744750977 18.83269500732422\n",
      "-11.425161361694336 16.51484489440918\n",
      "-10.506172180175781 16.0196533203125\n",
      "-10.319936752319336 14.667956352233887\n",
      "-13.697708129882812 19.293020248413086\n",
      "-15.455028533935547 22.81771469116211\n",
      "-9.93364143371582 16.4367618560791\n",
      "-9.214151382446289 18.593990325927734\n",
      "-14.697096824645996 12.432053565979004\n",
      "-6.693835735321045 15.66967487335205\n",
      "-11.68557071685791 13.192458152770996\n",
      "-13.976177215576172 14.569990158081055\n",
      "-8.857125282287598 28.083728790283203\n",
      "-11.388827323913574 27.83633804321289\n",
      "-19.37314796447754 8.376143455505371\n",
      "-11.082376480102539 15.846857070922852\n",
      "-12.739686965942383 17.30220603942871\n",
      "-10.357488632202148 14.518424034118652\n",
      "-8.826408386230469 16.90865707397461\n",
      "-15.040441513061523 19.852325439453125\n",
      "-17.17546272277832 24.33833885192871\n",
      "-11.616266250610352 13.25477123260498\n",
      "-9.180521011352539 17.633373260498047\n",
      "-12.223516464233398 14.054905891418457\n",
      "-11.170450210571289 14.305206298828125\n",
      "-12.412700653076172 11.75214672088623\n",
      "-13.189538955688477 14.673117637634277\n",
      "-8.399654388427734 24.047622680664062\n",
      "-8.188660621643066 15.675904273986816\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "-15.276172637939453 6.71931266784668\n",
      "-10.912471771240234 -5.288816928863525\n",
      "-10.831521034240723 9.261509895324707\n",
      "-2.865933895111084 14.14213752746582\n",
      "-0.8313133716583252 11.398100852966309\n",
      "-1.2336101531982422 10.233515739440918\n",
      "-5.727839946746826 10.209092140197754\n",
      "-10.912734985351562 10.174965858459473\n",
      "-0.014370683580636978 21.798076629638672\n",
      "-26.10298728942871 3.761051893234253\n",
      "4.18501091003418 0.9789688587188721\n",
      "3.793771266937256 12.94775104522705\n",
      "3.1241023540496826 13.109871864318848\n",
      "0.8241117000579834 12.320170402526855\n",
      "1.0762429237365723 14.6033296585083\n",
      "0.19451743364334106 12.24769115447998\n",
      "-0.19127678871154785 12.859572410583496\n",
      "2.3789360523223877 12.6777925491333\n",
      "0.08486080169677734 13.517854690551758\n",
      "2.478522539138794 7.707732200622559\n",
      "-1.3945012092590332 12.032845497131348\n",
      "-3.413954257965088 7.691689491271973\n",
      "0.5712206363677979 10.501930236816406\n",
      "2.056178331375122 10.437532424926758\n",
      "1.872604250907898 9.145552635192871\n",
      "-0.02161884680390358 10.280348777770996\n",
      "-2.602625608444214 17.358976364135742\n",
      "-7.116324424743652 35.13240432739258\n",
      "-2.6598398685455322 21.778335571289062\n",
      "-2.6314382553100586 20.153301239013672\n",
      "-4.871644973754883 21.93299102783203\n",
      "-4.751948356628418 22.646530151367188\n",
      "-5.219121932983398 22.371173858642578\n",
      "-6.194401741027832 20.240760803222656\n",
      "-7.1981048583984375 22.765260696411133\n",
      "-7.536686420440674 21.6452693939209\n",
      "-7.912981986999512 22.988147735595703\n",
      "-5.3461103439331055 14.250502586364746\n",
      "-2.3790273666381836 9.683481216430664\n",
      "-3.2398855686187744 12.812411308288574\n",
      "-8.1009521484375 5.955636501312256\n",
      "-14.160524368286133 8.44027328491211\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4155: error: (-215:Assertion failed) inv_scale_x > 0 in function 'cv::resize'\\n\",)\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "-10.323439598083496 3.1233632564544678\n",
      "-13.37843132019043 -0.6028945446014404\n",
      "-10.274698257446289 11.6445894241333\n",
      "-11.648956298828125 15.99460506439209\n",
      "-13.169084548950195 2.3072965145111084\n",
      "-3.2741246223449707 10.70433235168457\n",
      "2.7432916164398193 19.789104461669922\n",
      "0.2356216311454773 6.911190986633301\n",
      "-8.777708053588867 -1.5565378665924072\n",
      "-0.9180057048797607 10.342893600463867\n",
      "-1.045417070388794 17.662532806396484\n",
      "-28.76494598388672 19.867172241210938\n",
      "-0.9850707054138184 22.136985778808594\n",
      "1.0861546993255615 21.428096771240234\n",
      "-1.3570671081542969 14.557604789733887\n",
      "-4.186426162719727 19.097291946411133\n",
      "-3.508807420730591 18.97430419921875\n",
      "-6.060528755187988 20.974925994873047\n",
      "-4.308699607849121 18.412517547607422\n",
      "-3.638558864593506 18.764196395874023\n",
      "-2.904978036880493 18.610464096069336\n",
      "2.534757137298584 7.223437309265137\n",
      "3.5574259757995605 2.221364736557007\n",
      "3.4130208492279053 2.14827299118042\n",
      "1.7082017660140991 18.94082260131836\n",
      "-7.957492351531982 18.134714126586914\n",
      "-29.509906768798828 3.104112148284912\n",
      "-8.351044654846191 -12.831315040588379\n",
      "-2.0913617610931396 -18.454761505126953\n",
      "-5.253366470336914 7.22730827331543\n",
      "-3.1203689575195312 5.9161057472229\n",
      "-1.1603788137435913 7.203953742980957\n",
      "-1.3141229152679443 8.631532669067383\n",
      "-0.7619783282279968 8.253149032592773\n",
      "2.2423834800720215 -5.189502239227295\n",
      "1.8593310117721558 -4.173084259033203\n",
      "-0.8733417391777039 -4.5577473640441895\n",
      "-3.886751651763916 -6.8415303230285645\n",
      "0.37414413690567017 -7.014535903930664\n",
      "-2.9478602409362793 4.177374839782715\n",
      "-0.06140458956360817 10.577615737915039\n",
      "0.7234500646591187 10.933269500732422\n",
      "-2.7675557136535645 1.1762726306915283\n",
      "-20.238393783569336 4.573190212249756\n",
      "1.6379284858703613 4.933163642883301\n",
      "4.034010887145996 6.255162239074707\n",
      "-1.3506336212158203 0.030035754665732384\n",
      "-11.22867202758789 7.664800643920898\n",
      "-13.906379699707031 -1.8314580917358398\n",
      "-12.89808464050293 6.09761381149292\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "-16.217370986938477 -0.8823134899139404\n",
      "-9.555867195129395 5.102566719055176\n",
      "-7.972009181976318 12.287824630737305\n",
      "-2.1423027515411377 5.8353681564331055\n",
      "-1.6841555833816528 11.416236877441406\n",
      "-1.449859857559204 12.602846145629883\n",
      "-3.7808260917663574 7.8918304443359375\n",
      "-8.552124977111816 12.625244140625\n",
      "-16.9724063873291 3.5221283435821533\n",
      "-6.169211387634277 7.074282169342041\n",
      "-4.056118011474609 10.973237037658691\n",
      "-4.714422702789307 -6.011606693267822\n",
      "-5.476158142089844 -5.01149320602417\n",
      "-7.5811238288879395 -22.810070037841797\n",
      "-9.312459945678711 -18.141115188598633\n",
      "-5.77014684677124 -15.851799011230469\n",
      "-5.312763214111328 -16.361495971679688\n",
      "-4.1565937995910645 -14.049468040466309\n",
      "-12.63132095336914 -11.8331937789917\n",
      "-7.987251281738281 -13.295872688293457\n",
      "-6.619563102722168 -20.616809844970703\n",
      "-6.163699150085449 -20.1152286529541\n",
      "-7.374133110046387 -21.70756721496582\n",
      "-10.239702224731445 -23.153038024902344\n",
      "-7.271081924438477 -16.538415908813477\n",
      "-5.292927265167236 -18.41440200805664\n",
      "-5.522480010986328 -18.99539566040039\n",
      "-4.180302619934082 -19.816864013671875\n",
      "-4.725934028625488 -21.475759506225586\n",
      "-4.35797643661499 -20.811311721801758\n",
      "-7.7749128341674805 -17.80648422241211\n",
      "-6.699369430541992 -20.296741485595703\n",
      "-3.9361839294433594 -21.514930725097656\n",
      "-5.758543014526367 -18.709819793701172\n",
      "-6.490114688873291 -18.83855438232422\n",
      "-5.366370677947998 -18.871856689453125\n",
      "-4.363752841949463 -19.198347091674805\n",
      "-6.79643440246582 -19.83959197998047\n",
      "-7.250608921051025 -19.684961318969727\n",
      "-2.5410287380218506 -0.5605738162994385\n",
      "-7.120521545410156 0.03424670547246933\n",
      "-12.638628005981445 -1.276393175125122\n",
      "-12.23069953918457 7.416990280151367\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "(\"OpenCV(4.10.0) D:\\\\a\\\\opencv-python\\\\opencv-python\\\\opencv\\\\modules\\\\imgproc\\\\src\\\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\\n\",)\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "-5.713545322418213 24.407493591308594\n",
      "-9.358725547790527 34.33891296386719\n",
      "-16.948284149169922 16.9781551361084\n",
      "-18.924543380737305 25.00234603881836\n",
      "-15.195826530456543 23.546573638916016\n",
      "-13.691762924194336 19.700847625732422\n",
      "-13.933307647705078 14.984103202819824\n",
      "-13.841747283935547 19.275890350341797\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n",
      "NO face is detected!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "### Open camera ###\n",
    "\"\"\" cap = cv2.VideoCapture(0)\n",
    "detector = RetinaFace(0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "predictor = LandmarkPredictor(0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "head_pose_estimator = SixDRep(0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "detect_time = time.time()\n",
    "faces = None \"\"\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = RetinaFace(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "predictor = LandmarkPredictor(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "head_pose_estimator = SixDRep(gpu_id=0) #user gpu_id=-1 for Mac to indicate CPU\n",
    "detect_time = time.time()\n",
    "faces = None\n",
    "\n",
    "#cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "#cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                     transforms.Resize((70, 210)),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "net = SixthEyeNet()\n",
    "EYE_MODEL_PATH = '../eye-gaze-data-loader/models/sixth_eye_net_combined.pth'\n",
    "bw = False\n",
    "net.load_state_dict(torch.load(EYE_MODEL_PATH))\n",
    "net.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n = 0\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, live_frame = cap.read()\n",
    "        loop_time = time.time()\n",
    "        \n",
    "        ### NOTE: RGB values are normalized within RetinaFace ###\n",
    "        ### Detect faces if none exist ###\n",
    "        \n",
    "        # Calculate the time difference\n",
    "        elapsed_time = time.time() - detect_time\n",
    "\n",
    "        ### Initialise a black frame ###\n",
    "        black_frame = np.zeros_like(live_frame)\n",
    "\n",
    "        # Check if n seconds has passed: The shorter the elapsed time - the more face detections are done, but also the lower the fps and efficiency\n",
    "        if faces is None or elapsed_time >= 1:\n",
    "            faces = detector(live_frame, cv=True, threshold=0.5)\n",
    "            detect_time = time.time()\n",
    "        else:\n",
    "            ### This is an efficiency method of predicting the face bound-box - especially for live camera. It uses the min and max values from the results of the previous landmark 'predictor' function. Helps increase the fps rate ###\n",
    "            ### However, it will not detect new faces, or when a face has gone ###\n",
    "            faces = updated_bbox(landmarks)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"NO face is detected!\")\n",
    "            continue\n",
    "\n",
    "        ### Predict landmarks from face ###\n",
    "        landmarks = get_landmarks(live_frame, faces)\n",
    "\n",
    "        ### Estimate head pose from face ###\n",
    "        pose = get_head_pose(live_frame, faces)\n",
    "        \n",
    "        ### Draw landmarks (AND/OR) pose cube ###\n",
    "        black_frame = draw_landmarks_cv(black_frame, faces, landmarks)\n",
    "        #draw_head_pose_cube_cv(black_frame, faces, pose[0])\n",
    "\n",
    "        ###\n",
    "        affinity_frame = draw(live_frame, black_frame)\n",
    "\n",
    "        # Calculate and display FPS, Pitch, Yaw and Roll\n",
    "        fps = 1 / (time.time() - loop_time)\n",
    "        #cv2.putText(black_frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        #cv2.putText(black_frame, f\"Pitch: {pose[0]['pitch']:.2f}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        #cv2.putText(black_frame, f\"Yaw: {pose[0]['yaw']:.2f}\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        #cv2.putText(black_frame, f\"Roll: {pose[0]['roll']:.2f}\", (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        input_data = get_input_data(live_frame)\n",
    "        if input_data is not None:\n",
    "            if len(input_data) != 0:\n",
    "                for face in input_data:\n",
    "                    draw_eye_gaze(face, net, affinity_frame)\n",
    "\n",
    "        \n",
    "        ### Display the resulting frame ###\n",
    "        cv2.imshow('', affinity_frame)\n",
    "\n",
    "        ### Press 'q' to exit the video window ###\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "### Release the capture when done ###\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481b2eb-baea-4157-b664-8dfdcbdd64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sixdrepnet import SixDRepNet\n",
    "import sixdrepnet.utils as utils\n",
    "from opencv_transforms import transforms as cv_transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "crop_resize = cv_transforms.Compose([cv_transforms.Resize(224),\n",
    "                                    cv_transforms.CenterCrop(224)])\n",
    "\n",
    "normalize = cv_transforms.Compose([cv_transforms.ToTensor(),\n",
    "                                    cv_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "def chunk_generator(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def chunk_call(model, chunk_size, input_tensor):\n",
    "    outputs = []\n",
    "    for chunk in chunk_generator(input_tensor, chunk_size):\n",
    "        outputs.append(model(chunk))\n",
    "    if isinstance(outputs[0], torch.Tensor):\n",
    "        return torch.cat(outputs, dim=0)\n",
    "    else:\n",
    "        return flatten(outputs)\n",
    "\n",
    "class SixDRep:\n",
    "    def __init__(self, gpu_id: int= -1, dict_path: str='') -> None:\n",
    "        self.model = SixDRepNet(gpu_id=gpu_id, dict_path=dict_path)\n",
    "        if gpu_id == -1:\n",
    "            self.device = torch.device('cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cuda:{}'.format(gpu_id))\n",
    "\n",
    "    def plot_pose_cube(self, frame, box, yaw, pitch, roll):\n",
    "        x_min = int(box[0])\n",
    "        y_min = int(box[1])\n",
    "        x_max = int(box[2])\n",
    "        y_max = int(box[3])\n",
    "        bbox_width = abs(x_max - x_min)\n",
    "        bbox_height = abs(y_max - y_min)\n",
    "\n",
    "        x_min = max(0, x_min-int(0.2*bbox_height))\n",
    "        y_min = max(0, y_min-int(0.2*bbox_width))\n",
    "        x_max = x_max+int(0.2*bbox_height)\n",
    "        y_max = y_max+int(0.2*bbox_width)\n",
    "        utils.plot_pose_cube(frame,  yaw, pitch, roll, x_min + int(.5*(x_max-x_min)), y_min + int(.5*(y_max-y_min)), size=bbox_width)\n",
    "\n",
    "    def __call__(self, all_faces, frames, batch_size=None, input_face_type='tuple', update_dict=True):\n",
    "        '''\n",
    "        frames: list of np.ndarray, 0~255, uint8, rgb order\n",
    "        batch_size: int, if None, no chunking\n",
    "        input_face_type: str, 'tuple' or 'dict' or 'box'\n",
    "        update_dict: bool, if True, update the input dictionary with head pose\n",
    "        '''\n",
    "        # if update_dict:\n",
    "        #     assert input_face_type == 'dict', 'input_face_type should be dict when updating dictionary'\n",
    "\n",
    "        #assert len(frames) == len(all_faces) M\n",
    "        if batch_size is None:\n",
    "            batch_size = len(all_faces) # no chunking\n",
    "        imgs_for_model = []\n",
    "        metas = []\n",
    "        for face, i in zip(all_faces, range(len(frames))):\n",
    "            #for j, face in enumerate(faces): M\n",
    "            frame = frames #M\n",
    "            if input_face_type == 'tuple':\n",
    "                box = face[0]\n",
    "            elif input_face_type == 'dict':\n",
    "                box = face['box']\n",
    "            elif input_face_type == 'box':\n",
    "                box = face\n",
    "            x_min = int(box[0])\n",
    "            y_min = int(box[1])\n",
    "            x_max = int(box[2])\n",
    "            y_max = int(box[3])\n",
    "            \n",
    "            bbox_width = abs(x_max - x_min)\n",
    "            bbox_height = abs(y_max - y_min)\n",
    "\n",
    "            x_min = max(0, x_min-int(0.2*bbox_height))\n",
    "            y_min = max(0, y_min-int(0.2*bbox_width))\n",
    "            x_max = x_max+int(0.2*bbox_height)\n",
    "            y_max = y_max+int(0.2*bbox_width)\n",
    "            img = frame[y_min:y_max, x_min:x_max]\n",
    "            imgs_for_model.append(normalize(crop_resize(img)))\n",
    "            metas.append((i, 0, x_min, y_min, x_max, y_max, bbox_width, bbox_height))\n",
    "\n",
    "                # pitch, yaw, roll = model.predict(img)\n",
    "                # img = model.draw_axis(img, yaw, pitch, roll)\n",
    "                # frame[y_min:y_max, x_min:x_max] = img\n",
    "\n",
    "                # utils.plot_pose_cube(frame,  yaw, pitch, roll, x_min + int(.5*(\n",
    "                #             x_max-x_min)), y_min + int(.5*(y_max-y_min)), size=bbox_width)\n",
    "\n",
    "        imgs_for_model = torch.stack(imgs_for_model).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            pred = chunk_call(self.model.model, batch_size, imgs_for_model)\n",
    "\n",
    "        euler = utils.compute_euler_angles_from_rotation_matrices(pred)*180/np.pi\n",
    "        p = euler[:, 0].cpu().detach().numpy()\n",
    "        y = euler[:, 1].cpu().detach().numpy()\n",
    "        r = euler[:, 2].cpu().detach().numpy()\n",
    "\n",
    "        # reorganize the output\n",
    "        outputs = [] #[] for _ in range(len(frames)) M\n",
    "\n",
    "        for (i, j, x_min, y_min, x_max, y_max, bbox_width, bbox_height), pitch, yaw, roll in zip(metas, p, y, r):\n",
    "            #utils.plot_pose_cube(frames[i], yaw, pitch, roll, x_min + int(.5*(x_max-x_min)), y_min + int(.5*(y_max-y_min)), size=bbox_width)\n",
    "            head_pose = {\n",
    "                'pitch': pitch,\n",
    "                'yaw': yaw,\n",
    "                'roll': roll\n",
    "            }\n",
    "            outputs.append(head_pose)\n",
    "            if update_dict and input_face_type == 'dict':\n",
    "\n",
    "                all_faces[0]['head_pose'] = head_pose\n",
    "        #for faces, output in zip(all_faces, outputs):\n",
    "            #assert len(faces) == len(output)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4ddd2c23c291ca41a30efe192477b0967ab2f83f0d470686ada35863dfaa7bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
